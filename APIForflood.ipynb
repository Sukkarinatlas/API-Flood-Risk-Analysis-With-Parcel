{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวนแปลงเกษตรในกลุ่มอำเภอที่เลือก: 37396 แปลง\n",
      "จำนวนแปลงเกษตรตั้งต้น: 37396 แปลง\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1. โหลดข้อมูลแปลงเกษตร\n",
    "farms = gpd.read_file(r\"E:\\PythonFor_Flood\\drive-download-20260119T075939Z-3-001\\พระนครศรีอยุธยา.shp\")\n",
    "\n",
    "# 1.1 กรองข้อมูลก่อนไปขั้นตอนอื่น\n",
    "farms = farms[farms['a_name'] == 'ผักไห่'].copy()\n",
    "\n",
    "# กรองเฉพาะอำเภอที่ต้องการ เช่น บางปะอิน และ ผักไห่ ['บางปะอิน', 'ผักไห่']\n",
    "# target_districts = ['ผักไห่']\n",
    "# farms = farms[farms['a_name'].isin(target_districts)].copy()\n",
    "\n",
    "print(f\"จำนวนแปลงเกษตรในกลุ่มอำเภอที่เลือก: {len(farms)} แปลง\")\n",
    "print(f\"จำนวนแปลงเกษตรตั้งต้น: {len(farms)} แปลง\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a549315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กำลังตรวจสอบและซ่อมแซม Geometry (Fix Geometry)...\n",
      "พบ Geometry ที่มีปัญหา: 0 แปลง\n",
      "Geometry ทั้งหมดสมบูรณ์\n"
     ]
    }
   ],
   "source": [
    "from shapely.validation import make_valid # นำเข้าฟังก์ชัน fix geometry\n",
    "\n",
    "# 2.---Fix Geometry (เหมือน Fix Geometry ใน QGIS) ---\n",
    "print(\"กำลังตรวจสอบและซ่อมแซม Geometry (Fix Geometry)...\")\n",
    "\n",
    "# ตรวจสอบว่ามีแปลงที่ Invalid หรือไม่\n",
    "invalid_count = (~farms.is_valid).sum()\n",
    "print(f\"พบ Geometry ที่มีปัญหา: {invalid_count:,} แปลง\")\n",
    "\n",
    "if invalid_count > 0:\n",
    "    # ใช้ .make_valid() เพื่อซ่อมแซมรูปทรง)\n",
    "    farms['geometry'] = farms['geometry'].apply(lambda geom: make_valid(geom) if not geom.is_valid else geom)\n",
    "    print(\"ซ่อมแซม Geometry เรียบร้อยแล้ว\")\n",
    "else:\n",
    "    print(\"Geometry ทั้งหมดสมบูรณ์\")\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc38f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- เริ่มดึงข้อมูลแบบละเอียดสูงสุด (Target: 9,128 รายการ) ---\n",
      "รอบที่ 1/10: ดึงได้ 1,000 รายการ | สะสมรวม: 1,000\n",
      "รอบที่ 2/10: ดึงได้ 1,000 รายการ | สะสมรวม: 2,000\n",
      "รอบที่ 3/10: ดึงได้ 1,000 รายการ | สะสมรวม: 3,000\n",
      "รอบที่ 4/10: ดึงได้ 1,000 รายการ | สะสมรวม: 4,000\n",
      "รอบที่ 5/10: ดึงได้ 1,000 รายการ | สะสมรวม: 5,000\n",
      "รอบที่ 6/10: ดึงได้ 1,000 รายการ | สะสมรวม: 6,000\n",
      "รอบที่ 7/10: ดึงได้ 1,000 รายการ | สะสมรวม: 7,000\n",
      "รอบที่ 8/10: ดึงได้ 1,000 รายการ | สะสมรวม: 8,000\n",
      "รอบที่ 9 (พยายามครั้งที่ 1): เจอค่าว่าง... กำลังลองใหม่\n",
      "รอบที่ 9/10: ดึงได้ 1,000 รายการ | สะสมรวม: 9,000\n",
      "รอบที่ 10/10: ดึงได้ 128 รายการ | สะสมรวม: 9,128\n",
      "\n",
      "✅ ดึงเสร็จสิ้น! ได้ข้อมูลทั้งหมด: 9,128 จาก 9,128 รายการ\n",
      "freq\n",
      "1     835\n",
      "2    3645\n",
      "3    4300\n",
      "4     348\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "\n",
    "# 3. ฟังก์ชันดึง API แบบละเอียด (ป้องกันข้อมูลหลุด)\n",
    "def get_bbox(gdf):\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    return f\"{minx},{miny},{maxx},{maxy}\"\n",
    "\n",
    "bbox = get_bbox(farms)\n",
    "api_key = \"YOUR_API-KEY\"\n",
    "collection_id = \"66b07c8034c2963abcdb9bb8\"\n",
    "\n",
    "# 1. เช็กจำนวนทั้งหมดอีกครั้ง\n",
    "initial_url = f\"https://api-gateway.gistda.or.th/api/2.0/resources/features/flood-freq?api_key={api_key}&bbox={bbox}&collectionCreatedBy={collection_id}&limit=1&offset=0\"\n",
    "res = requests.get(initial_url).json()\n",
    "total_features = res.get('numberMatched', 0)\n",
    "\n",
    "# 2. ปรับ Limit ให้เล็กลง (ใช้ 1000 หรือ 2000 เพื่อความเสถียรสูงสุด)\n",
    "limit = 1000 \n",
    "total_pages = math.ceil(total_features / limit)\n",
    "all_features = []\n",
    "\n",
    "print(f\"--- เริ่มดึงข้อมูลแบบละเอียดสูงสุด (Target: {total_features:,} รายการ) ---\")\n",
    "\n",
    "for i in range(total_pages):\n",
    "    offset = i * limit\n",
    "    url = f\"https://api-gateway.gistda.or.th/api/2.0/resources/features/flood-freq?api_key={api_key}&bbox={bbox}&collectionCreatedBy={collection_id}&limit={limit}&offset={offset}\"\n",
    "    \n",
    "    # ระบบ Retry: ถ้าเจอค่าว่างให้ลองใหม่สูงสุด 3 ครั้ง\n",
    "    for attempt in range(1, 4):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=60)\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "            \n",
    "            if len(features) > 0:\n",
    "                all_features.extend(features)\n",
    "                print(f\"รอบที่ {i+1}/{total_pages}: ดึงได้ {len(features):,} รายการ | สะสมรวม: {len(all_features):,}\")\n",
    "                break # ได้ข้อมูลแล้ว ไปรอบถัดไป\n",
    "            else:\n",
    "                # ถ้าเป็นหน้าท้ายๆ แล้วไม่มีข้อมูลจริงๆ ให้หยุด\n",
    "                if offset >= total_features:\n",
    "                    break\n",
    "                print(f\"รอบที่ {i+1} (พยายามครั้งที่ {attempt}): เจอค่าว่าง... กำลังลองใหม่\")\n",
    "                time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"รอบที่ {i+1} พลาด: {e}\")\n",
    "            time.sleep(3)\n",
    "            \n",
    "    time.sleep(0.5) #กันโดน Block\n",
    "\n",
    "# 3. ตรวจสอบและสร้าง GeoDataFrame\n",
    "if len(all_features) > 0:\n",
    "    flood_gdf = gpd.GeoDataFrame.from_features(all_features, crs=\"EPSG:4326\")\n",
    "    flood_gdf.to_file(r\"E:\\PythonFor_Flood\\flood_data_temp.gpkg\", driver=\"GPKG\")\n",
    "    print(f\"ดึงเสร็จสิ้น! ได้ข้อมูลทั้งหมด: {len(flood_gdf):,} จาก {total_features:,} รายการ\")\n",
    "    print(flood_gdf['freq'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"ไม่สามารถดึงข้อมูลได้เลย\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52fa4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farms CRS: EPSG:32647\n",
      "Flood CRS: EPSG:32647\n"
     ]
    }
   ],
   "source": [
    "# 4. แปลงพิกัดเป็น UTM เพื่อความแม่นยำ\n",
    "farms_utm = farms.to_crs(epsg=32647)\n",
    "flood_utm = flood_gdf.to_crs(epsg=32647)\n",
    "#เช็กว่า CRS ตรงกันจริงไหมก่อน Join\n",
    "print(f\"Farms CRS: {farms_utm.crs}\")\n",
    "print(f\"Flood CRS: {flood_utm.crs}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8b8e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ผลลัพธ์หลังการ Join (ยังไม่ Clean) ---\n",
      "           act type_name detail_nam plant_date year_act           p_name  \\\n",
      "145  163730806      ข้าว   ข้าวเจ้า   20220504     2565  พระนครศรีอยุธยา   \n",
      "145  163730806      ข้าว   ข้าวเจ้า   20220504     2565  พระนครศรีอยุธยา   \n",
      "185  166191184      ข้าว   ข้าวเจ้า   20220531     2565  พระนครศรีอยุธยา   \n",
      "185  166191184      ข้าว   ข้าวเจ้า   20220531     2565  พระนครศรีอยุธยา   \n",
      "185  166191184      ข้าว   ข้าวเจ้า   20220531     2565  พระนครศรีอยุธยา   \n",
      "\n",
      "     a_name t_name moo  freq  \n",
      "145  ผักไห่   อมฤต   1     3  \n",
      "145  ผักไห่   อมฤต   1     4  \n",
      "185  ผักไห่   อมฤต   9     4  \n",
      "185  ผักไห่   อมฤต   9     3  \n",
      "185  ผักไห่   อมฤต   9     3  \n",
      "จากทั้งหมด 73,923 แปลง | พบพื้นที่น้ำท่วม 73,923 แปลง\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.sjoin แบบ left: เก็บทุกแปลงไว้ (Eliminate missing data จากการ Intersect)\n",
    "joined_data = gpd.sjoin(farms_utm, flood_utm[['freq', 'geometry']], how='left', predicate='intersects')\n",
    "\n",
    "#ลองเช็กจำนวนแปลงที่ \"ท่วม\" เทียบกับ \"ทั้งหมด\"\n",
    "total = len(joined_data)\n",
    "flooded = joined_data['freq'].notna().sum()\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- ผลลัพธ์หลังการ Join (ยังไม่ Clean) ---\")\n",
    "print(joined_data[['act','type_name', 'detail_nam','plant_date','year_act','p_name', 'a_name','t_name','moo','freq']].head(5))\n",
    "print(f\"จากทั้งหมด {total:,} แปลง | พบพื้นที่น้ำท่วม {flooded:,} แปลง\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a64b3cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- สรุปการจัดการข้อมูลซ้ำ ---\n",
      "จำนวนข้อมูลที่ Join มาทั้งหมด: 73,923 แถว\n",
      "จำนวนแปลงเกษตรที่ Clean แล้ว: 37,396 แปลง\n",
      "จำนวนแปลงที่ลดลงไป (ตัวซ้ำ): 36,527 แถว\n"
     ]
    }
   ],
   "source": [
    "# 6. เรียงลำดับความสำคัญ: \n",
    "# - เลขประจำกิจกรรม (act) \n",
    "# - ปีล่าสุด (year_act) -> เรียงจากมากไปน้อย (False)\n",
    "# - ความเสี่ยงสูงสุด (freq) -> เรียงจากมากไปน้อย (False)\n",
    "joined_data_sorted = joined_data.sort_values(\n",
    "    by=['act', 'year_act', 'freq'], \n",
    "    ascending=[True, False, False]\n",
    ")\n",
    "\n",
    "# 7. ลบตัวซ้ำ (Deduplicate)\n",
    "# จะเก็บเฉพาะ \"แถวแรก\" ของแต่ละ 'act' (ซึ่งก็คือแถวที่มีปีใหม่สุดและ freq สูงสุด)\n",
    "cleaned_farms = joined_data_sorted.drop_duplicates(subset=['act'], keep='first').copy()\n",
    "\n",
    "print(f\"--- สรุปการจัดการข้อมูลซ้ำ ---\")\n",
    "print(f\"จำนวนข้อมูลที่ Join มาทั้งหมด: {len(joined_data):,} แถว\")\n",
    "print(f\"จำนวนแปลงเกษตรที่ Clean แล้ว: {len(cleaned_farms):,} แปลง\")\n",
    "print(f\"จำนวนแปลงที่ลดลงไป (ตัวซ้ำ): {len(joined_data) - len(cleaned_farms):,} แถว\")\n",
    "\n",
    "# ตรวจสอบว่าจำนวนแปลงกลับมาใกล้เคียงค่าตั้งต้นหรือยัง (ควรกลับมาเท่ากับจํานวนขั้นตอนแรก)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c01fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ตัวอย่างผลลัพธ์การจัดกลุ่มพืชและความเสี่ยง ---\n",
      "              act type_name detail_nam crop_group risk_level_new\n",
      "133545  123115255      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "119303  123188568      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "140692  123190978      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "90848   123235786      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "24930   123253109      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "57058   123300247      ข้าว   ข้าวเจ้า     1-ข้าว              3\n",
      "66750   123300384      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "111159  123300559      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "75124   123301178      ข้าว   ข้าวเจ้า     1-ข้าว              4\n",
      "17753   123301229      ข้าว   ข้าวเจ้า     1-ข้าว              4\n"
     ]
    }
   ],
   "source": [
    "# 8. จัดกลุ่มพืช 5 กลุ่ม (Group Mapping)\n",
    "def crop_classification(crop):\n",
    "    if pd.isna(crop): return '5-อื่นๆ'\n",
    "    crop = str(crop)\n",
    "    if 'ข้าว' in crop: return '1-ข้าว'\n",
    "    if 'พืชไร่' in crop: return '2-พืชไร่'\n",
    "    if 'พืชสวน' in crop: return '3-พืชสวน'\n",
    "    if 'พืชผัก' in crop: return '4-พืชผัก'\n",
    "    return '5-อื่นๆ' # เพิ่มบรรทัดนี้กันเหนียวเผื่อข้อมูลไม่เข้าเงื่อนไขด้านบน\n",
    "    \n",
    "\n",
    "cleaned_farms['crop_group'] = cleaned_farms['type_name'].apply(crop_classification)\n",
    "\n",
    "#  วิเคราะห์สถานะความเสี่ยง (ใช้ปีข้อมูล และความถี่น้ำท่วม)\n",
    "# นิยาม: ถ้า freq มีค่า (ไม่เป็น NaN) = มีความเสี่ยง\n",
    "def assess_risk(row):\n",
    "    if pd.isna(row['freq']):\n",
    "        return '0' #-ไม่เสี่ยง\n",
    "    if row['freq'] >= 4: return '4' #-เสี่ยงสูงมาก\n",
    "    if row['freq'] >= 3: return '3'#-เสี่ยงสูง\n",
    "    if row['freq'] >= 2: return '2'#-เสี่ยงปานกลาง\n",
    "    if row['freq'] >= 1: return '1'#-เสี่ยงน้อย\n",
    "\n",
    "cleaned_farms['risk_level_new'] = cleaned_farms.apply(assess_risk, axis=1)\n",
    "\n",
    "print(\"--- ตัวอย่างผลลัพธ์การจัดกลุ่มพืชและความเสี่ยง ---\")\n",
    "print(cleaned_farms[['act','type_name','detail_nam', 'crop_group', 'risk_level_new']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1332b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ตารางสรุปจำนวนแปลงแยกตามระดับความเสี่ยง ---\n",
      "risk_level_new\n",
      "1      669\n",
      "2      840\n",
      "3     3197\n",
      "4    32690\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 9. สรุปข้อมูลเป็นตาราง (แทนการใช้กราฟเพื่อเลี่ยงปัญหาฟอนต์ภาษาไทย)\n",
    "print(\"--- ตารางสรุปจำนวนแปลงแยกตามระดับความเสี่ยง ---\")\n",
    "summary_table = cleaned_farms['risk_level_new'].value_counts().sort_index()\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fafc74ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- กำลังส่งออกไฟล์ ---\n",
      "ส่งออกเป็นไฟล์ .csv เรียบร้อยแล้ว (สามารถใช้ Excel เปิดได้เลย)\n"
     ]
    }
   ],
   "source": [
    "# 10. คัดเลือกเฉพาะ Field ที่ต้องการ (จัดระเบียบข้อมูล)\n",
    "export_cols = [\n",
    "    'p_name', 'a_name', 't_name', 'moo', 'act', 'year_act',\n",
    "    'detail_nam', 'crop_group', 'plant_date', 'produce_da', \n",
    "    'freq', 'risk_level_new', 'geometry'\n",
    "]\n",
    "final_output = cleaned_farms[[c for c in export_cols if c in cleaned_farms.columns]].copy()\n",
    "\n",
    "#  ส่งออกไฟล์\n",
    "print(\"\\n--- กำลังส่งออกไฟล์ ---\")\n",
    "\n",
    "# ส่งออกเป็น GeoPackage\n",
    "final_output.to_file(r\"E:\\PythonFor_Flood\\Flood_Analysis_Ayutthaya.gpkg\", driver=\"GPKG\")\n",
    "\n",
    "# ส่งออก.csv \n",
    "final_output.drop(columns='geometry').to_csv(r\"E:\\PythonFor_Flood\\Flood_Risk_Report_Ayutthaya.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ส่งออกเป็นไฟล์ .csv เรียบร้อยแล้ว (สามารถใช้ Excel เปิดได้เลย)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
